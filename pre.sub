#!/bin/sh

#SBATCH --job-name="clip"
#SBATCH --partition=a100
#SBATCH --gpus=1
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --mem=50G
#SBATCH --time=0-24:00:00
#SBATCH -o slurm_logs/slurm.%N.%j.out 
#SBATCH -e slurm_logs/slurm.%N.%j.err

launcher=launch.sh

script=pretrain.py
args="--batch_size 8 --lr 3e-4 --data_ver 2"

arguments="$launcher torchrun --nproc_per_node=1 --master_port=12345 $script $args"
apptainer exec docker://container-registry.surrey.ac.uk/shared-containers/sobhan-sqa bash $arguments > pretrain.out